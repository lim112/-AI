{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install glob\n",
    "!pip install random\n",
    "!pip install matplotlib.patches\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from matplotlib.patches import Rectangle\n",
    "from lxml import etree\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Image_Label_Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('/content/drive/MyDrive/Colab Notebooks/ai프로젝트/input/images/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/content/drive/MyDrive/Colab Notebooks/ai프로젝트/input/label/label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = glob.glob('/content/drive/MyDrive/Colab Notebooks/ai프로젝트/input/images/crease/*.jpg')\n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmls_path = glob.glob('/content/drive/MyDrive/Colab Notebooks/ai프로젝트/input/images/crease/*.xml')\n",
    "len(xmls_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    " #glob 모듈을 사용하여 특정 경로 내에서 .jpg 파일을 모두 찾음\n",
    "# image_path = glob.glob('/content/drive/MyDrive/project/steel_data/images/*/*.jpg')\n",
    "image_path = glob.glob('/content/drive/MyDrive/Colab Notebooks/ai프로젝트/input/images/crease/*.jpg')\n",
    "len(image_path)\n",
    "\n",
    "img_names = [img.split('/')[-1].split('.jpg')[0] for img in image_path]\n",
    "print(img_names)\n",
    " #glob 모듈을 사용하여 특정 경로 내에서 .xml 파일을 모두 찾음\n",
    "# xmls_path = glob.glob('/content/drive/MyDrive/project/steel_data/label/label/*.xml')\n",
    "xmls_path = glob.glob('/content/drive/MyDrive/Colab Notebooks/ai프로젝트/input/images/crease/*.xml')\n",
    "# print(xmls_path[0])\n",
    "xml_names = [xml.split('/')[-1].split('.xml')[0] for xml in xmls_path]\n",
    "print(xml_names)\n",
    "#XML 파일 이름만 추출\n",
    "#p.split('/')[-1] 분리된 리스트에서 마지막 요소를 선택\n",
    "#.split('.')[0]: 파일 이름을 . 기준으로 분리하여 확장자를 제거하고, 순수한 파일 이름만 추출\n",
    "xmls_train = [p.split('/')[-1].split('.')[0] for p in xmls_path]\n",
    "\n",
    "imgs_train = [img for img in image_path if img.split('/')[-1].split('.jpg')[0] in xml_names]\n",
    "\n",
    "xmls_path = [xml for xml in xmls_path if xml.split('/')[-1].split('.xml')[0] in img_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xmls_path),len(imgs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels names\n",
    "names = [x.split(\"/\")[-2] for x in imgs_train]\n",
    "names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.DataFrame(names,columns=['Types'])\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehot for mutiple classes\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "Class = names['Types'].unique()\n",
    "Class_dict = dict(zip(Class, range(1,len(Class)+1)))\n",
    "names['str'] = names['Types'].apply(lambda x: Class_dict[x])\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(list(Class_dict.values()))\n",
    "transformed_labels = lb.transform(names['str'])\n",
    "y_bin_labels = []\n",
    "\n",
    "for i in range(transformed_labels.shape[1]):\n",
    "    y_bin_labels.append('str' + str(i))\n",
    "    names['str' + str(i)] = transformed_labels[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.drop('str',axis=1,inplace=True)\n",
    "names.drop('Types',axis=1,inplace=True)\n",
    "names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Extraction & Input pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis rectangular box value in xmls\n",
    "def to_labels(path):\n",
    "    xml = open('{}'.format(path)).read()                         #read xml in path\n",
    "    sel = etree.HTML(xml)\n",
    "    width = int(sel.xpath('//size/width/text()')[0])     #extract the width/height\n",
    "    height = int(sel.xpath('//size/height/text()')[0])    #extract the x,y value\n",
    "    xmin = int(sel.xpath('//bndbox/xmin/text()')[0])\n",
    "    xmax = int(sel.xpath('//bndbox/xmax/text()')[0])\n",
    "    ymin = int(sel.xpath('//bndbox/ymin/text()')[0])\n",
    "    ymax = int(sel.xpath('//bndbox/ymax/text()')[0])\n",
    "    return [xmin/width, ymin/height, xmax/width, ymax/height]   #return the four relative points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set value to labels\n",
    "labels = [to_labels(path) for path in xmls_path]\n",
    "labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set four labels as outputs\n",
    "out1,out2,out3,out4 = list(zip(*labels))\n",
    "#convert to np.array\n",
    "out1 = np.array(out1)\n",
    "out2 = np.array(out2)\n",
    "out3 = np.array(out3)\n",
    "out4 = np.array(out4)\n",
    "label = np.array(names.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label to tf.data\n",
    "label_datasets = tf.data.Dataset.from_tensor_slices((out1,out2,out3,out4,label))\n",
    "label_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_image function\n",
    "def load_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image,3)\n",
    "    image = tf.image.resize(image,[224,224])\n",
    "    image = tf.cast(image/127.5-1,tf.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(imgs_train)\n",
    "dataset = dataset.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_label = tf.data.Dataset.zip((dataset,label_datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch constant\n",
    "BATCH_SIZE = 16\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch extraction and shuffle\n",
    "dataset_label = dataset_label.repeat().shuffle(500).batch(BATCH_SIZE)\n",
    "dataset_label = dataset_label.prefetch(AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "test_count = int(len(imgs_train)*0.2)\n",
    "train_count = len(imgs_train) - test_count\n",
    "test_count,train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "test_count = int(len(imgs_train)*0.2)\n",
    "train_count = len(imgs_train) - test_count\n",
    "# test_count,train_count\n",
    "\n",
    "train_dataset = dataset_label.skip(test_count)\n",
    "test_dataset = dataset_label.take(test_count)\n",
    "\n",
    "# train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dict = {v:k for k,v in Class_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check from train_data\n",
    "for img, label in train_dataset.take(1):\n",
    "    plt.imshow(keras.preprocessing.image.array_to_img(img[0]))\n",
    "    out1,out2,out3,out4,out5 = label\n",
    "    xmin,ymin,xmax,ymax = out1[0].numpy()*224,out2[0].numpy()*224,out3[0].numpy()*224,out4[0].numpy()*224\n",
    "    rect = Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),fill=False,color='r')\n",
    "    ax = plt.gca()\n",
    "    ax.axes.add_patch(rect)\n",
    "    pred_imglist = []\n",
    "    pred_imglist.append(species_dict[np.argmax(out5[0])+1])\n",
    "    plt.title(pred_imglist)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 The VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution based\n",
    "conv = keras.applications.xception.Xception(weights='imagenet',\n",
    "                                            include_top=False,\n",
    "                                            input_shape=(224,224,3),\n",
    "                                            pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open trainable\n",
    "conv.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define Conv + FC structure\n",
    "inputs = keras.Input(shape=(224,224,3))\n",
    "x = conv(inputs)\n",
    "x1 = keras.layers.Dense(1024,activation='relu')(x)\n",
    "x1 = keras.layers.Dense(512,activation='relu')(x1)\n",
    "\n",
    "\n",
    "out1 = keras.layers.Dense(1,name='out1')(x1)\n",
    "out2 = keras.layers.Dense(1,name='out2')(x1)\n",
    "out3 = keras.layers.Dense(1,name='out3')(x1)\n",
    "out4 = keras.layers.Dense(1,name='out4')(x1)\n",
    "\n",
    "x2 = keras.layers.Dense(1024,activation='relu')(x)\n",
    "x2 = keras.layers.Dropout(0.5)(x2)\n",
    "x2 = keras.layers.Dense(512,activation='relu')(x2)\n",
    "out_class = keras.layers.Dense(10,activation='softmax',name='out_item')(x2)\n",
    "\n",
    "out = [out1,out2,out3,out4,out_class]\n",
    "\n",
    "model = keras.models.Model(inputs=inputs,outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Class_dict 정의\n",
    "Class_dict = {\n",
    "    'crease': 1,\n",
    "    'rolled_pit': 2,\n",
    "    'welding_line': 3,\n",
    "    'water_spot': 4,\n",
    "    'silk_spot': 5,\n",
    "    'punching': 6,\n",
    "    'oil_spot': 7,\n",
    "    'waist_folding': 8,\n",
    "    'inclusion': 9,\n",
    "    'crescent_gap': 10\n",
    "}\n",
    "\n",
    "# 이미지에 대한 클래스 레이블을 Class_dict의 정수값으로 변환하여 valid_labels에 저장\n",
    "image_classes = ['crease', 'welding_line', 'oil_spot', 'crease']\n",
    "\n",
    "valid_labels = [Class_dict[cls] for cls in image_classes]\n",
    "\n",
    "print(valid_labels)  # 정수형 레이블\n",
    "\n",
    "# 정답 레이블을 원핫 인코딩하지 않고 정수형 레이블 그대로 사용\n",
    "# 모델 컴파일 (각 출력에 맞는 loss와 metrics 제공)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # 초기 학습률 설정\n",
    "              loss={\n",
    "                  'out1': 'mse',\n",
    "                  'out2': 'mse',\n",
    "                  'out3': 'mse',\n",
    "                  'out4': 'mse',\n",
    "                  'out_item': 'sparse_categorical_crossentropy'  # 정수형 레이블 사용\n",
    "              },\n",
    "              metrics={\n",
    "                  'out1': 'mae',\n",
    "                  'out2': 'mae',\n",
    "                  'out3': 'mae',\n",
    "                  'out4': 'mae',\n",
    "                  'out_item': 'accuracy'  # 정확도 사용\n",
    "              })\n",
    "\n",
    "# 학습률 감소 콜백 설정\n",
    "lr_reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=6, factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    train_dataset,  # 학습 데이터셋\n",
    "    steps_per_epoch=train_count // BATCH_SIZE,  # 학습 데이터에서 스텝 수 계산\n",
    "    epochs=30,  # 에포크 수 설정\n",
    "    validation_data=test_dataset,  # 검증 데이터셋\n",
    "    validation_steps=test_count // BATCH_SIZE,  # 검증 데이터에서 스텝 수 계산\n",
    "    callbacks=[lr_reduce]  # 학습률 감소 콜백 추가\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training visualization\n",
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch']=history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.plot(hist['epoch'],hist['loss'],\n",
    "            label='Train Loss')\n",
    "    plt.plot(hist['epoch'],hist['val_loss'],\n",
    "            label='Val Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Val_MAE')\n",
    "    plt.plot(hist['epoch'],hist['val_out1_mae'],\n",
    "            label='Out1_mae')\n",
    "    plt.plot(hist['epoch'],hist['val_out2_mae'],\n",
    "            label='Out2_mae')\n",
    "    plt.plot(hist['epoch'],hist['val_out3_mae'],\n",
    "            label='Out3_mae')\n",
    "    plt.plot(hist['epoch'],hist['val_out4_mae'],\n",
    "            label='Out4_mae')\n",
    "    plt.legend()\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Val_Item_Acc')\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Val_Item_Acc')\n",
    "    plt.plot(hist['epoch'], hist['val_out_item_accuracy'], label='Out5_acc')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('out1_mae in test:{}'.format(mae[6]))\n",
    "# print('out2_mae in test:{}'.format(mae[8]))\n",
    "# print('out3_mae in test:{}'.format(mae[10]))\n",
    "# print('out4_mae in test:{}'.format(mae[12]))\n",
    "# print('class_label in test:{}'.format(mae[15]))\n",
    "print('out1_mae in test:{}'.format(mae[0]))\n",
    "print('out2_mae in test:{}'.format(mae[1]))\n",
    "print('out3_mae in test:{}'.format(mae[2]))\n",
    "print('out4_mae in test:{}'.format(mae[3]))\n",
    "print('class_label in test:{}'.format(mae[5]))  # out_item_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:\\KDT_SF6\\비전ai\\model_save/class_location_test_crease.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dict = {v:k for k,v in Class_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,24))\n",
    "# for img,_ in train_dataset.take(1):\n",
    "#     out1, out2, out3, out4, out5 = model.predict(img)\n",
    "#     for i in range(3):\n",
    "#         plt.axis('off')\n",
    "#         plt.subplot(3, 1, i+1)\n",
    "#         plt.imshow(keras.preprocessing.image.array_to_img(img[i]))\n",
    "\n",
    "#         pred_class_index = np.argmax(out5[i]) + 1  # 예측된 클래스 인덱스\n",
    "#         print(f\"Predicted class index: {pred_class_index}\")\n",
    "\n",
    "#         pred_imglist = []\n",
    "#         # species_dict에서 예측된 클래스 인덱스가 존재하는지 확인\n",
    "#         if pred_class_index in species_dict:\n",
    "#             pred_imglist.append(species_dict[pred_class_index])\n",
    "#         else:\n",
    "#             pred_imglist.append(f\"Unknown class {pred_class_index}\")\n",
    "\n",
    "#         plt.title(pred_imglist)\n",
    "\n",
    "#         xmin, ymin, xmax, ymax = out1[i] * 224, out2[i] * 224, out3[i] * 224, out4[i] * 224\n",
    "#         rect = Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), fill=False, color='r')\n",
    "#         ax = plt.gca()\n",
    "#         ax.axes.add_patch(rect)\n",
    "plt.figure(figsize=(10,24))\n",
    "\n",
    "# 모델에서 예측한 출력(out5)이 클래스 예측 결과라고 가정\n",
    "for img, _ in train_dataset.take(1):\n",
    "    out1, out2, out3, out4, out5 = model.predict(img)\n",
    "\n",
    "    # 3개의 이미지를 순회\n",
    "    for i in range(3):\n",
    "        plt.axis('off')  # 축 표시 제거\n",
    "        plt.subplot(3, 1, i+1)\n",
    "\n",
    "        # 이미지 시각화\n",
    "        plt.imshow(keras.preprocessing.image.array_to_img(img[i]))\n",
    "\n",
    "        # 예측된 클래스 인덱스\n",
    "        pred_class_index = np.argmax(out5[i]) + 1  # species_dict가 1부터 시작한다면\n",
    "\n",
    "        # 클래스가 항상 species_dict에 존재한다고 가정하고 처리\n",
    "        pred_imglist = [species_dict[pred_class_index]]\n",
    "\n",
    "        # 제목 설정\n",
    "        plt.title(pred_imglist)\n",
    "\n",
    "        # 바운딩 박스 그리기\n",
    "        xmin, ymin, xmax, ymax = out1[i] * 224, out2[i] * 224, out3[i] * 224, out4[i] * 224\n",
    "        rect = Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), fill=False, color='r')\n",
    "        ax = plt.gca()  # 현재의 축 가져오기\n",
    "        ax.axes.add_patch(rect)\n",
    "\n",
    "# 시각화한 이미지 출력\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install matplotlib\n",
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install glob\n",
    "# !pip install random\n",
    "# !pip install matplotlib.patches\n",
    "# !pip install lxml\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "from matplotlib.patches import Rectangle\n",
    "from lxml import etree\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline\n",
    "결함s = ['crease','crescent_gap','oil_spot','rolled_pit','punching_hole','silk_spot','inclusion','waist folding','water_spot','welding_line']\n",
    "# 1. 로드 데이터\n",
    "결함 = 'rolled_pit'\n",
    "os.listdir('/content/drive/MyDrive/비전ai/archive/images/images/images')\n",
    "os.listdir('/content/drive/MyDrive/비전ai/archive/label/xml_single_bndbox')\n",
    "# image_path = glob.glob('/content/drive/MyDrive/비전ai/archive/images/images/images/crease/*.jpg')\n",
    "# # len(image_path)\n",
    "\n",
    "# xmls_path = glob.glob('/content/drive/MyDrive/비전ai/archive/label/xml_single_bndbox/*.xml')\n",
    "# len(xmls_path)\n",
    "# for i in 결함:\n",
    "#   try:\n",
    "  #glob 모듈을 사용하여 특정 경로 내에서 .jpg 파일을 모두 찾음\n",
    "  # image_path = glob.glob('/content/drive/MyDrive/project/steel_data/images/*/*.jpg')\n",
    "image_path = glob.glob(f'/content/drive/MyDrive/비전ai/archive/images/images/images/{결함}/*.jpg')\n",
    "# len(image_path)\n",
    "\n",
    "img_names = [img.split('/')[-1].split('.jpg')[0] for img in image_path]\n",
    "print(img_names)\n",
    "#glob 모듈을 사용하여 특정 경로 내에서 .xml 파일을 모두 찾음\n",
    "# xmls_path = glob.glob('/content/drive/MyDrive/project/steel_data/label/label/*.xml')\n",
    "xmls_path = glob.glob('/content/drive/MyDrive/비전ai/archive/label/label/*.xml')\n",
    "# print(xmls_path[0])\n",
    "xml_names = [xml.split('/')[-1].split('.xml')[0] for xml in xmls_path]\n",
    "print(xml_names)\n",
    "#XML 파일 이름만 추출\n",
    "#p.split('/')[-1] 분리된 리스트에서 마지막 요소를 선택\n",
    "#.split('.')[0]: 파일 이름을 . 기준으로 분리하여 확장자를 제거하고, 순수한 파일 이름만 추출\n",
    "xmls_train = [p.split('/')[-1].split('.')[0] for p in xmls_path]\n",
    "\n",
    "imgs_train = [img for img in image_path if img.split('/')[-1].split('.jpg')[0] in xml_names]\n",
    "\n",
    "xmls_path = [xml for xml in xmls_path if xml.split('/')[-1].split('.xml')[0] in img_names]\n",
    "names = [x.split(\"/\")[-2] for x in imgs_train]\n",
    "names = pd.DataFrame(names,columns=['Types'])\n",
    "#onehot for mutiple classes\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "Class = names['Types'].unique()\n",
    "Class_dict = dict(zip(Class, range(1,len(Class)+1)))\n",
    "\n",
    "names['str'] = names['Types'].apply(lambda x: Class_dict[x])\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(list(Class_dict.values()))\n",
    "\n",
    "transformed_labels = lb.transform(names['str'])\n",
    "\n",
    "y_bin_labels = []\n",
    "\n",
    "for i in range(transformed_labels.shape[1]):\n",
    "    y_bin_labels.append('str' + str(i))\n",
    "    names['str' + str(i)] = transformed_labels[:, i]\n",
    "\n",
    "names.drop('str',axis=1,inplace=True)\n",
    "names.drop('Types',axis=1,inplace=True)\n",
    "# names.head()\n",
    "\n",
    "#analysis rectangular box value in xmls\n",
    "def to_labels(path):\n",
    "    xml = open('{}'.format(path)).read()                         #read xml in path\n",
    "    sel = etree.HTML(xml)\n",
    "    width = int(sel.xpath('//size/width/text()')[0])     #extract the width/height\n",
    "    height = int(sel.xpath('//size/height/text()')[0])    #extract the x,y value\n",
    "    xmin = int(sel.xpath('//bndbox/xmin/text()')[0])\n",
    "    xmax = int(sel.xpath('//bndbox/xmax/text()')[0])\n",
    "    ymin = int(sel.xpath('//bndbox/ymin/text()')[0])\n",
    "    ymax = int(sel.xpath('//bndbox/ymax/text()')[0])\n",
    "    return [xmin/width, ymin/height, xmax/width, ymax/height]   #return the four relative points\n",
    "\n",
    "#set value to labels\n",
    "labels = [to_labels(path) for path in xmls_path]\n",
    "# labels[:3]\n",
    "\n",
    "#set four labels as outputs\n",
    "out1,out2,out3,out4 = list(zip(*labels))\n",
    "#convert to np.array\n",
    "out1 = np.array(out1)\n",
    "out2 = np.array(out2)\n",
    "out3 = np.array(out3)\n",
    "out4 = np.array(out4)\n",
    "label = np.array(names.values)\n",
    "\n",
    "#label to tf.data\n",
    "label_datasets = tf.data.Dataset.from_tensor_slices((out1,out2,out3,out4,label))\n",
    "\n",
    "#def load_image function\n",
    "def load_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image,3)\n",
    "    image = tf.image.resize(image,[224,224])\n",
    "    image = tf.cast(image/127.5-1,tf.float32)\n",
    "    return image\n",
    "\n",
    "#build dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(imgs_train)\n",
    "dataset = dataset.map(load_image)\n",
    "\n",
    "dataset_label = tf.data.Dataset.zip((dataset,label_datasets))\n",
    "\n",
    "#batch constant\n",
    "BATCH_SIZE = 16\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "#batch extraction and shuffle\n",
    "dataset_label = dataset_label.repeat().shuffle(500).batch(BATCH_SIZE)\n",
    "dataset_label = dataset_label.prefetch(AUTO)\n",
    "\n",
    "#Split dataset\n",
    "test_count = int(len(imgs_train)*0.2)\n",
    "train_count = len(imgs_train) - test_count\n",
    "# test_count,train_count\n",
    "\n",
    "train_dataset = dataset_label.skip(test_count)\n",
    "test_dataset = dataset_label.take(test_count)\n",
    "\n",
    "species_dict = {v:k for k,v in Class_dict.items()}\n",
    "\n",
    "#check from train_data\n",
    "for img, label in train_dataset.take(1):\n",
    "    plt.imshow(keras.preprocessing.image.array_to_img(img[0]))\n",
    "    out1,out2,out3,out4,out5 = label\n",
    "    xmin,ymin,xmax,ymax = out1[0].numpy()*224,out2[0].numpy()*224,out3[0].numpy()*224,out4[0].numpy()*224\n",
    "    rect = Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),fill=False,color='r')\n",
    "    ax = plt.gca()\n",
    "    ax.axes.add_patch(rect)\n",
    "    pred_imglist = []\n",
    "    pred_imglist.append(species_dict[np.argmax(out5[0])+1])\n",
    "    plt.title(pred_imglist)\n",
    "    plt.show()\n",
    "\n",
    "# 2. Model Building\n",
    "# 2.1 The VGG16 model\n",
    "#Convolution based\n",
    "conv = keras.applications.xception.Xception(weights='imagenet',\n",
    "                                            include_top=False,\n",
    "                                            input_shape=(224,224,3),\n",
    "                                            pooling='avg')\n",
    "#open trainable\n",
    "conv.trainable = True\n",
    "\n",
    "#define Conv + FC structure\n",
    "inputs = keras.Input(shape=(224,224,3))\n",
    "x = conv(inputs)\n",
    "x1 = keras.layers.Dense(1024,activation='relu')(x)\n",
    "x1 = keras.layers.Dense(512,activation='relu')(x1)\n",
    "\n",
    "\n",
    "out1 = keras.layers.Dense(1,name='out1')(x1)\n",
    "out2 = keras.layers.Dense(1,name='out2')(x1)\n",
    "out3 = keras.layers.Dense(1,name='out3')(x1)\n",
    "out4 = keras.layers.Dense(1,name='out4')(x1)\n",
    "\n",
    "x2 = keras.layers.Dense(1024,activation='relu')(x)\n",
    "x2 = keras.layers.Dropout(0.5)(x2)\n",
    "x2 = keras.layers.Dense(512,activation='relu')(x2)\n",
    "out_class = keras.layers.Dense(10,activation='softmax',name='out_item')(x2)\n",
    "\n",
    "out = [out1,out2,out3,out4,out_class]\n",
    "\n",
    "model = keras.models.Model(inputs=inputs,outputs=out)\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Class_dict 정의\n",
    "Class_dict = {\n",
    "    'crease': 1,\n",
    "    'rolled_pit':2,\n",
    "    'welding_line': 3,\n",
    "    'water_spot': 4,\n",
    "    'silk_spot': 5,\n",
    "    'punching_hole': 6,\n",
    "    'oil_spot': 7,\n",
    "    'waist folding': 8,\n",
    "    'inclusion': 9,\n",
    "    'crescent_gap': 10\n",
    "}\n",
    "\n",
    "# 이미지에 대한 클래스 레이블을 Class_dict의 정수값으로 변환하여 valid_labels에 저장\n",
    "image_classes =['crease','crescent_gap','oil_spot','rolled_pit','punching_hole','silk_spot','inclusion','waist folding','water_spot','welding_line']\n",
    "valid_labels = [Class_dict[cls] for cls in image_classes]\n",
    "\n",
    "print(valid_labels)  # 정수형 레이블\n",
    "\n",
    "# 정답 레이블을 원핫 인코딩하지 않고 정수형 레이블 그대로 사용\n",
    "# 모델 컴파일 (각 출력에 맞는 loss와 metrics 제공)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.002),  # 초기 학습률 설정\n",
    "              loss={\n",
    "                  'out1': 'mse',\n",
    "                  'out2': 'mse',\n",
    "                  'out3': 'mse',\n",
    "                  'out4': 'mse',\n",
    "                  'out_item': 'sparse_categorical_crossentropy'  # 정수형 레이블 사용\n",
    "              },\n",
    "              metrics={\n",
    "                  'out1': 'mae',\n",
    "                  'out2': 'mae',\n",
    "                  'out3': 'mae',\n",
    "                  'out4': 'mae',\n",
    "                  'out_item': 'accuracy'  # 정확도 사용\n",
    "              })\n",
    "\n",
    "# 학습률 감소 콜백 설정\n",
    "lr_reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=6, factor=0.5, min_lr=1e-8)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    train_dataset,  # 학습 데이터셋\n",
    "    steps_per_epoch=train_count // BATCH_SIZE,  # 학습 데이터에서 스텝 수 계산\n",
    "    epochs=50,  # 에포크 수 설정\n",
    "    validation_data=test_dataset,  # 검증 데이터셋\n",
    "    validation_steps=test_count // BATCH_SIZE,  # 검증 데이터에서 스텝 수 계산\n",
    "    callbacks=[lr_reduce]  # 학습률 감소 콜백 추가\n",
    ")\n",
    "#training visualization\n",
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch']=history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.plot(hist['epoch'],hist['loss'],\n",
    "            label='Train Loss')\n",
    "    plt.plot(hist['epoch'],hist['val_loss'],\n",
    "            label='Val Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Val_MAE')\n",
    "    plt.plot(hist['epoch'],hist['val_out1_mae'],\n",
    "            label='Out1_mae')\n",
    "    plt.plot(hist['epoch'],hist['val_out2_mae'],\n",
    "            label='Out2_mae')\n",
    "    plt.plot(hist['epoch'],hist['val_out3_mae'],\n",
    "            label='Out3_mae')\n",
    "    plt.plot(hist['epoch'],hist['val_out4_mae'],\n",
    "            label='Out4_mae')\n",
    "    plt.legend()\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.xlabel('Epoch')\n",
    "    # plt.ylabel('Val_Item_Acc')\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Val_Item_Acc')\n",
    "    plt.plot(hist['epoch'], hist['val_out_item_accuracy'], label='Out5_acc')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "mae = model.evaluate(test_dataset)\n",
    "\n",
    "# print('out1_mae in test:{}'.format(mae[6]))\n",
    "# print('out2_mae in test:{}'.format(mae[8]))\n",
    "# print('out3_mae in test:{}'.format(mae[10]))\n",
    "# print('out4_mae in test:{}'.format(mae[12]))\n",
    "# print('class_label in test:{}'.format(mae[15]))\n",
    "print('out1_mae in test:{}'.format(mae[0]))\n",
    "print('out2_mae in test:{}'.format(mae[1]))\n",
    "print('out3_mae in test:{}'.format(mae[2]))\n",
    "print('out4_mae in test:{}'.format(mae[3]))\n",
    "print('class_label in test:{}'.format(mae[5]))  # out_item_accuracy\n",
    "\n",
    "model.save(f\"/content/drive/MyDrive/비전ai/archive/model_save/class_location_test3_{결함}.h5\")\n",
    "model.save(f\"/content/drive/MyDrive/비전ai/archive/model_save/class_location_test3_{결함}.keras\")\n",
    "species_dict = {v:k for k,v in Class_dict.items()}\n",
    "\n",
    "# plt.figure(figsize=(10,24))\n",
    "# for img,_ in train_dataset.take(1):\n",
    "#     out1, out2, out3, out4, out5 = model.predict(img)\n",
    "#     for i in range(3):\n",
    "#         plt.axis('off')\n",
    "#         plt.subplot(3, 1, i+1)\n",
    "#         plt.imshow(keras.preprocessing.image.array_to_img(img[i]))\n",
    "\n",
    "#         pred_class_index = np.argmax(out5[i]) + 1  # 예측된 클래스 인덱스\n",
    "#         print(f\"Predicted class index: {pred_class_index}\")\n",
    "\n",
    "#         pred_imglist = []\n",
    "#         # species_dict에서 예측된 클래스 인덱스가 존재하는지 확인\n",
    "#         if pred_class_index in species_dict:\n",
    "#             pred_imglist.append(species_dict[pred_class_index])\n",
    "#         else:\n",
    "#             pred_imglist.append(f\"Unknown class {pred_class_index}\")\n",
    "\n",
    "#         plt.title(pred_imglist)\n",
    "\n",
    "#         xmin, ymin, xmax, ymax = out1[i] * 224, out2[i] * 224, out3[i] * 224, out4[i] * 224\n",
    "#         rect = Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), fill=False, color='r')\n",
    "#         ax = plt.gca()\n",
    "#         ax.axes.add_patch(rect)\n",
    "plt.figure(figsize=(10,24))\n",
    "\n",
    "# 모델에서 예측한 출력(out5)이 클래스 예측 결과라고 가정\n",
    "for img, _ in train_dataset.take(1):\n",
    "    out1, out2, out3, out4, out5 = model.predict(img)\n",
    "\n",
    "    # 3개의 이미지를 순회\n",
    "    for i in range(10):\n",
    "        plt.axis('off')  # 축 표시 제거\n",
    "        plt.subplot(10, 1, i+1)\n",
    "\n",
    "        # 이미지 시각화\n",
    "        plt.imshow(keras.preprocessing.image.array_to_img(img[i]))\n",
    "\n",
    "        # 예측된 클래스 인덱스\n",
    "        pred_class_index = np.argmax(out5[i]) + 1  # species_dict가 1부터 시작한다면\n",
    "\n",
    "        # 클래스가 항상 species_dict에 존재한다고 가정하고 처리\n",
    "        pred_imglist = [species_dict[pred_class_index]]\n",
    "\n",
    "        # 제목 설정\n",
    "        plt.title(pred_imglist)\n",
    "\n",
    "        # 바운딩 박스 그리기\n",
    "        xmin, ymin, xmax, ymax = out1[i] * 224, out2[i] * 224, out3[i] * 224, out4[i] * 224\n",
    "        rect = Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), fill=False, color='r')\n",
    "        ax = plt.gca()  # 현재의 축 가져오기\n",
    "        ax.axes.add_patch(rect)\n",
    "\n",
    "# 시각화한 이미지 출력\n",
    "plt.show()\n",
    "# except:\n",
    "#   print(f'{i}폴더는 생성하지 못했습니다')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
